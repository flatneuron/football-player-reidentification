{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "154MB7P7GbSPRBl1a_3MZx-xF8Emqnidr",
      "authorship_tag": "ABX9TyPLBUAr02JLEeOxHaZZgfuU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flatneuron/football-player-reidentification/blob/main/reid_model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchreid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_Ha4Uv5UlWX",
        "outputId": "3cd6e16b-6aeb-401a-b29a-a85c4f7e1201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchreid\n",
            "  Downloading torchreid-0.2.5.tar.gz (92 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/92.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torchreid\n",
            "  Building wheel for torchreid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchreid: filename=torchreid-0.2.5-py3-none-any.whl size=144324 sha256=a460651519913b2970e4700b28c61a538fad48ec9c00f7fe5e1c3fcf68d36289\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/dc/08/b478469bab07b5ede9e962968ebe3c8961c10c5fc106a6c697\n",
            "Successfully built torchreid\n",
            "Installing collected packages: torchreid\n",
            "Successfully installed torchreid-0.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import os.path as osp\n",
        "from torchreid.reid.data.datasets.dataset import ImageDataset\n",
        "\n",
        "class MyReidDataset(ImageDataset):\n",
        "    dataset_dir = 'drive/MyDrive/stealth mode/reid-data_mine'\n",
        "\n",
        "    def __init__(self, root='', **kwargs):\n",
        "        # Resolve absolute paths\n",
        "        self.root = osp.abspath(osp.expanduser(root))\n",
        "        self.dataset_dir = osp.join(self.root, self.dataset_dir)\n",
        "\n",
        "        # 1) collect all camera-folder names and person-folder names\n",
        "        splits = [\"train\", \"query\", \"gallery\"]\n",
        "        cam_names = set()\n",
        "        pid_names = set()\n",
        "\n",
        "        for split in splits:\n",
        "            split_dir = osp.join(self.dataset_dir, split)\n",
        "            if not osp.isdir(split_dir):\n",
        "                raise ValueError(f\"Expected '{split_dir}' to exist.\")\n",
        "            for cam in os.listdir(split_dir):\n",
        "                cam_dir = osp.join(split_dir, cam)\n",
        "                if not osp.isdir(cam_dir):\n",
        "                    continue\n",
        "                cam_names.add(cam)\n",
        "                for pid in os.listdir(cam_dir):\n",
        "                    pid_dir = osp.join(cam_dir, pid)\n",
        "                    if osp.isdir(pid_dir):\n",
        "                        pid_names.add(pid)\n",
        "\n",
        "        # 2) build zero-based mappings\n",
        "        cam_list = sorted(cam_names)\n",
        "        pid_list = sorted(pid_names)\n",
        "        cam2label = {cam: idx for idx, cam in enumerate(cam_list)}\n",
        "        pid2label = {pid: idx for idx, pid in enumerate(pid_list)}\n",
        "\n",
        "        # 3) helper to parse each split into (img_path, pid, camid)\n",
        "        def parse_split(split):\n",
        "            data = []\n",
        "            split_dir = osp.join(self.dataset_dir, split)\n",
        "            for cam in os.listdir(split_dir):\n",
        "                cam_dir = osp.join(split_dir, cam)\n",
        "                if not osp.isdir(cam_dir):\n",
        "                    continue\n",
        "                camid = cam2label[cam]\n",
        "                for pid in os.listdir(cam_dir):\n",
        "                    pid_dir = osp.join(cam_dir, pid)\n",
        "                    if not osp.isdir(pid_dir):\n",
        "                        continue\n",
        "                    pidid = pid2label[pid]\n",
        "                    # collect all image files under this pid folder\n",
        "                    for fname in os.listdir(pid_dir):\n",
        "                        if not fname.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
        "                            continue\n",
        "                        img_path = osp.join(pid_dir, fname)\n",
        "                        data.append((img_path, pidid, camid))\n",
        "            return data\n",
        "\n",
        "        # 4) generate the three splits\n",
        "        train = parse_split(\"train\")\n",
        "        query = parse_split(\"query\")\n",
        "        gallery = parse_split(\"gallery\")\n",
        "\n",
        "        def check_pid_consistency(query, gallery):\n",
        "          query_pids = set([pid for _, pid, _ in query])\n",
        "          gallery_pids = set([pid for _, pid, _ in gallery])\n",
        "\n",
        "          missing = query_pids - gallery_pids\n",
        "          if missing:\n",
        "              print(\"ðŸš« Missing PIDs in gallery:\", missing)\n",
        "          else:\n",
        "              print(\"âœ… All query PIDs are present in gallery!\")\n",
        "\n",
        "        # Call it like this\n",
        "        check_pid_consistency(query, gallery)\n",
        "\n",
        "        # 5) pass to super\n",
        "        super(MyReidDataset, self).__init__(train, query, gallery, **kwargs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvGz5QGMijtT",
        "outputId": "474209cb-20d3-41e3-933c-eb7fa803acf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchreid/reid/metrics/rank.py:11: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchreid\n",
        "torchreid.reid.data.datasets.register_image_dataset('MY-reid-dataset1', MyReidDataset)\n",
        "ROOT_DIR = ''\n",
        "datamanager = torchreid.data.ImageDataManager(\n",
        "    root=ROOT_DIR,\n",
        "    sources='MY-reid-dataset1',\n",
        "    transforms=None,\n",
        "    workers=2,\n",
        "    height=256,\n",
        "    width=256\n",
        ")\n",
        "\n",
        "\n",
        "######################################\n",
        "# You will get the following details as output\n",
        "# Building train transforms ...\n",
        "# + resize to 256x256\n",
        "# + to torch tensor of range [0, 1]\n",
        "# + normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "# Building test transforms ...\n",
        "# + resize to 256x256\n",
        "# + to torch tensor of range [0, 1]\n",
        "# + normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "# => Loading train (source) dataset\n",
        "# => Loaded Pigs\n",
        "#   -------------------------------------------\n",
        "#   subset   | # ids | # tracklets | # cameras\n",
        "#   -------------------------------------------\n",
        "#   train    |     3 |        1227 |         4\n",
        "#   query    |     3 |          48 |         4\n",
        "#   gallery  |     3 |        1255 |         4\n",
        "#   -------------------------------------------\n",
        "\n",
        "\n",
        "#   **************** Summary ****************\n",
        "#   source             : ['pigs']\n",
        "#   # source datasets  : 1\n",
        "#   # source ids       : 3\n",
        "#   # source tracklets : 1227\n",
        "#   # source cameras   : 4\n",
        "#   target             : ['pigs']\n",
        "#   *****************************************"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc62a3a2-7e08-4f1e-de5e-bbe5a5511204",
        "id": "FbC5Paz3kqiT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building train transforms ...\n",
            "+ resize to 256x256\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "Building test transforms ...\n",
            "+ resize to 256x256\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "=> Loading train (source) dataset\n",
            "âœ… All query PIDs are present in gallery!\n",
            "=> Loaded MyReidDataset\n",
            "  ----------------------------------------\n",
            "  subset   | # ids | # images | # cameras\n",
            "  ----------------------------------------\n",
            "  train    |    19 |     1325 |         1\n",
            "  query    |    19 |      276 |         1\n",
            "  gallery  |    19 |      305 |         1\n",
            "  ----------------------------------------\n",
            "=> Loading test (target) dataset\n",
            "âœ… All query PIDs are present in gallery!\n",
            "=> Loaded MyReidDataset\n",
            "  ----------------------------------------\n",
            "  subset   | # ids | # images | # cameras\n",
            "  ----------------------------------------\n",
            "  train    |    19 |     1325 |         1\n",
            "  query    |    19 |      276 |         1\n",
            "  gallery  |    19 |      305 |         1\n",
            "  ----------------------------------------\n",
            "âœ… All query PIDs are present in gallery!\n",
            "\n",
            "\n",
            "  **************** Summary ****************\n",
            "  source            : ['MY-reid-dataset1']\n",
            "  # source datasets : 1\n",
            "  # source ids      : 19\n",
            "  # source images   : 1325\n",
            "  # source cameras  : 1\n",
            "  target            : ['MY-reid-dataset1']\n",
            "  *****************************************\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchreid.reid.models import build_model\n",
        "import torch\n",
        "model = build_model(\n",
        "    name='osnet_x1_0',                # any key from __model_factory\n",
        "    num_classes=datamanager.num_train_pids,  # number of training IDs (ReID classes)\n",
        "    loss='softmax',                   # or 'triplet', or both as 'softmax+triplet'\n",
        "    pretrained=True,                  # use ImageNet pretrained weights\n",
        "    use_gpu=torch.cuda.is_available()  # move model to GPU if available\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuCsoLq6Ui-z",
        "outputId": "72f4e166-5954-4f47-b222-685b0adcdeaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1LaG1EJpHrxdAxKnSCJ_i0u-nbxSAeiFY\n",
            "To: /root/.cache/torch/checkpoints/osnet_x1_0_imagenet.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10.9M/10.9M [00:00<00:00, 112MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded imagenet pretrained weights from \"/root/.cache/torch/checkpoints/osnet_x1_0_imagenet.pth\"\n",
            "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torchreid.optim.build_optimizer(\n",
        "    model,\n",
        "    optim='adam',\n",
        "    lr=0.0003\n",
        ")"
      ],
      "metadata": {
        "id": "RrRjuhNHnP6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = torchreid.optim.build_lr_scheduler(\n",
        "    optimizer,\n",
        "    lr_scheduler='single_step',\n",
        "    stepsize=20\n",
        ")\n"
      ],
      "metadata": {
        "id": "fdf9lfWZnZx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchreid\n",
        "ROOT_DIR = ''\n",
        "datamanager = torchreid.data.ImageDataManager(\n",
        "    root=ROOT_DIR,\n",
        "    sources='MY-reid-dataset1',\n",
        "    transforms=None,\n",
        "    workers=2,\n",
        "    height=256,\n",
        "    width=256\n",
        ")\n",
        "\n",
        "\n",
        "######################################\n",
        "# You will get the following details as output\n",
        "# Building train transforms ...\n",
        "# + resize to 256x256\n",
        "# + to torch tensor of range [0, 1]\n",
        "# + normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "# Building test transforms ...\n",
        "# + resize to 256x256\n",
        "# + to torch tensor of range [0, 1]\n",
        "# + normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "# => Loading train (source) dataset\n",
        "# => Loaded Pigs\n",
        "#   -------------------------------------------\n",
        "#   subset   | # ids | # tracklets | # cameras\n",
        "#   -------------------------------------------\n",
        "#   train    |     3 |        1227 |         4\n",
        "#   query    |     3 |          48 |         4\n",
        "#   gallery  |     3 |        1255 |         4\n",
        "#   -------------------------------------------\n",
        "\n",
        "\n",
        "#   **************** Summary ****************\n",
        "#   source             : ['pigs']\n",
        "#   # source datasets  : 1\n",
        "#   # source ids       : 3\n",
        "#   # source tracklets : 1227\n",
        "#   # source cameras   : 4\n",
        "#   target             : ['pigs']\n",
        "#   *****************************************"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ql06laJwncMF",
        "outputId": "eea2d43c-7129-4691-c0f2-79a151059717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building train transforms ...\n",
            "+ resize to 256x256\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "Building test transforms ...\n",
            "+ resize to 256x256\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "=> Loading train (source) dataset\n",
            "âœ… All query PIDs are present in gallery!\n",
            "=> Loaded MyReidDataset\n",
            "  ----------------------------------------\n",
            "  subset   | # ids | # images | # cameras\n",
            "  ----------------------------------------\n",
            "  train    |    19 |     1325 |         1\n",
            "  query    |    19 |      276 |         1\n",
            "  gallery  |    19 |      305 |         1\n",
            "  ----------------------------------------\n",
            "=> Loading test (target) dataset\n",
            "âœ… All query PIDs are present in gallery!\n",
            "=> Loaded MyReidDataset\n",
            "  ----------------------------------------\n",
            "  subset   | # ids | # images | # cameras\n",
            "  ----------------------------------------\n",
            "  train    |    19 |     1325 |         1\n",
            "  query    |    19 |      276 |         1\n",
            "  gallery  |    19 |      305 |         1\n",
            "  ----------------------------------------\n",
            "âœ… All query PIDs are present in gallery!\n",
            "\n",
            "\n",
            "  **************** Summary ****************\n",
            "  source            : ['MY-reid-dataset1']\n",
            "  # source datasets : 1\n",
            "  # source ids      : 19\n",
            "  # source images   : 1325\n",
            "  # source cameras  : 1\n",
            "  target            : ['MY-reid-dataset1']\n",
            "  *****************************************\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchreid\n",
        "engine = torchreid.reid.engine.image.ImageSoftmaxEngine(\n",
        "    datamanager,\n",
        "    model,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    label_smooth=True,\n",
        "    use_gpu=torch.cuda.is_available()\n",
        ")\n",
        "\n",
        "# Move model to GPU if available\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "engine.run(\n",
        "    save_dir='og/osnet',\n",
        "    max_epoch=1,\n",
        "    eval_freq=1,\n",
        "    print_freq=2,\n",
        "    test_only=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hOSsdhEnl0k",
        "outputId": "3453a1dc-db79-40ab-dea6-b50c5db1ce4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Start training\n",
            "epoch: [1/1][2/41]\ttime 0.319 (6.580)\tdata 0.001 (5.349)\teta 0:04:16\tloss 2.8605 (2.8960)\tacc 15.6250 (10.9375)\tlr 0.000300\n",
            "epoch: [1/1][4/41]\ttime 1.526 (5.821)\tdata 1.208 (5.032)\teta 0:03:35\tloss 2.7176 (2.8327)\tacc 18.7500 (14.8438)\tlr 0.000300\n",
            "epoch: [1/1][6/41]\ttime 1.953 (5.645)\tdata 1.638 (5.003)\teta 0:03:17\tloss 2.5214 (2.7304)\tacc 46.8750 (27.0833)\tlr 0.000300\n",
            "epoch: [1/1][8/41]\ttime 0.593 (5.544)\tdata 0.275 (4.974)\teta 0:03:02\tloss 2.3996 (2.6673)\tacc 40.6250 (29.6875)\tlr 0.000300\n",
            "epoch: [1/1][10/41]\ttime 0.836 (5.504)\tdata 0.518 (4.977)\teta 0:02:50\tloss 2.2792 (2.5865)\tacc 50.0000 (34.6875)\tlr 0.000300\n",
            "epoch: [1/1][12/41]\ttime 0.321 (5.562)\tdata 0.000 (5.063)\teta 0:02:41\tloss 2.1032 (2.5063)\tacc 56.2500 (38.5417)\tlr 0.000300\n",
            "epoch: [1/1][14/41]\ttime 0.320 (5.487)\tdata 0.000 (5.010)\teta 0:02:28\tloss 2.0110 (2.4357)\tacc 65.6250 (42.4107)\tlr 0.000300\n",
            "epoch: [1/1][16/41]\ttime 0.326 (5.429)\tdata 0.001 (4.968)\teta 0:02:15\tloss 1.9423 (2.3822)\tacc 68.7500 (45.1172)\tlr 0.000300\n",
            "epoch: [1/1][18/41]\ttime 0.323 (5.447)\tdata 0.000 (4.996)\teta 0:02:05\tloss 1.6961 (2.3154)\tacc 78.1250 (47.9167)\tlr 0.000300\n",
            "epoch: [1/1][20/41]\ttime 0.325 (5.436)\tdata 0.000 (4.995)\teta 0:01:54\tloss 1.6367 (2.2518)\tacc 84.3750 (50.7812)\tlr 0.000300\n",
            "epoch: [1/1][22/41]\ttime 0.326 (5.417)\tdata 0.000 (4.984)\teta 0:01:42\tloss 1.6400 (2.1947)\tacc 71.8750 (52.8409)\tlr 0.000300\n",
            "epoch: [1/1][24/41]\ttime 0.323 (5.424)\tdata 0.000 (4.998)\teta 0:01:32\tloss 1.7207 (2.1490)\tacc 68.7500 (54.5573)\tlr 0.000300\n",
            "epoch: [1/1][26/41]\ttime 0.329 (5.425)\tdata 0.001 (5.004)\teta 0:01:21\tloss 1.5768 (2.1054)\tacc 75.0000 (55.8894)\tlr 0.000300\n",
            "epoch: [1/1][28/41]\ttime 0.328 (5.440)\tdata 0.001 (5.024)\teta 0:01:10\tloss 1.2913 (2.0520)\tacc 87.5000 (57.9241)\tlr 0.000300\n",
            "epoch: [1/1][30/41]\ttime 0.327 (5.405)\tdata 0.000 (4.993)\teta 0:00:59\tloss 1.2927 (2.0066)\tacc 84.3750 (59.2708)\tlr 0.000300\n",
            "epoch: [1/1][32/41]\ttime 0.331 (5.418)\tdata 0.000 (5.011)\teta 0:00:48\tloss 1.5210 (1.9741)\tacc 75.0000 (60.3516)\tlr 0.000300\n",
            "epoch: [1/1][34/41]\ttime 0.329 (5.425)\tdata 0.000 (5.020)\teta 0:00:37\tloss 1.2239 (1.9384)\tacc 84.3750 (61.4890)\tlr 0.000300\n",
            "epoch: [1/1][36/41]\ttime 1.022 (5.439)\tdata 0.693 (5.037)\teta 0:00:27\tloss 1.2817 (1.8980)\tacc 81.2500 (62.8472)\tlr 0.000300\n",
            "epoch: [1/1][38/41]\ttime 0.332 (5.468)\tdata 0.001 (5.068)\teta 0:00:16\tloss 1.2550 (1.8671)\tacc 81.2500 (63.6513)\tlr 0.000300\n",
            "epoch: [1/1][40/41]\ttime 0.334 (5.527)\tdata 0.000 (5.128)\teta 0:00:05\tloss 1.3658 (1.8357)\tacc 71.8750 (64.5312)\tlr 0.000300\n",
            "=> Final test\n",
            "##### Evaluating MY-reid-dataset1 (source) #####\n",
            "Extracting features from query set ...\n",
            "Done, obtained 276-by-512 matrix\n",
            "Extracting features from gallery set ...\n",
            "Done, obtained 305-by-512 matrix\n",
            "Speed: 0.0217 sec/batch\n",
            "Computing distance matrix with metric=euclidean ...\n",
            "Computing CMC and mAP ...\n",
            "** Results **\n",
            "mAP: 78.8%\n",
            "CMC curve\n",
            "Rank-1  : 89.9%\n",
            "Rank-5  : 95.7%\n",
            "Rank-10 : 96.7%\n",
            "Rank-20 : 98.6%\n",
            "Checkpoint saved to \"og/osnet/model/model.pth.tar-1\"\n",
            "Elapsed 0:05:35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r og /content/drive/MyDrive/stealth\\ mode/\n"
      ],
      "metadata": {
        "id": "t4brd6Lsqvvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AHILrQgE7kE1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}